{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import classic_lda, lda_vae\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import time \n",
    "import plotnine as pn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mmread(\"data/mackosko_scrnaseq_preprocessed.mtx\").toarray()\n",
    "rownames = pd.read_csv(\"data/mackosko_scrnaseq_preprocessed.mtx.rownames\")\n",
    "colnames = pd.read_csv(\"data/mackosko_scrnaseq_preprocessed.mtx.colnames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat, test_mat = train_test_split(data, test_size = .25)\n",
    "vocab_size = 5000\n",
    "ntopics = 500\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vae_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m vae_topic_props, vae_train_loss, vae_test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlda_vae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_vae_lda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mntopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m vae_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m vae_coherence \u001b[38;5;241m=\u001b[39m lda_vae\u001b[38;5;241m.\u001b[39mUCI_coherence(vae_topic_props, test_mat, \u001b[38;5;241m25\u001b[39m,transparent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/vss2134/scTopic/model/lda_vae.py:151\u001b[0m, in \u001b[0;36mtrain_vae_lda\u001b[0;34m(train_data, test_data, vsize, ntopics, n_epochs)\u001b[0m\n\u001b[1;32m    149\u001b[0m x\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m ld_vae\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 151\u001b[0m mu,logsigma, predicted_word_props,_,_ \u001b[39m=\u001b[39m ld_vae(x)\n\u001b[1;32m    152\u001b[0m sigma \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(logsigma)\n\u001b[1;32m    153\u001b[0m c_loss \u001b[39m=\u001b[39m loss(x, predicted_word_props, prior_mean, prior_var, mu, sigma, logsigma, ntopics)\n",
      "File \u001b[0;32m/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/vss2134/scTopic/model/lda_vae.py:94\u001b[0m, in \u001b[0;36mVAE_LDA.forward\u001b[0;34m(self, observed_word_counts)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observed_word_counts):\n\u001b[0;32m---> 94\u001b[0m     mu,logsigma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference_net(observed_word_counts)\n\u001b[1;32m     95\u001b[0m     predicted_word_counts, topics_per_doc, topics_per_word \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerative_net(mu,logsigma)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m mu,logsigma, predicted_word_counts, topics_per_doc, topics_per_word\n",
      "File \u001b[0;32m/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/vss2134/scTopic/model/lda_vae.py:34\u001b[0m, in \u001b[0;36mInferenceNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m\"\"\"Forward pass.\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layer(x)\n\u001b[0;32m---> 34\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactivation(x)\n\u001b[1;32m     35\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden1(x)\n\u001b[1;32m     36\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(x)\n",
      "File \u001b[0;32m/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/torch/nn/modules/activation.py:98\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/torch/nn/functional.py:1442\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1443\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae_start = time.time()\n",
    "vae_topic_props, vae_train_loss, vae_test_loss = lda_vae.train_vae_lda(train_mat, test_mat, vocab_size,ntopics, n_epochs )\n",
    "vae_end = time.time()\n",
    "vae_coherence = lda_vae.UCI_coherence(vae_topic_props, test_mat, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:48<00:00,  4.62it/s]\n"
     ]
    }
   ],
   "source": [
    "cl_start = time.time()\n",
    "cl_topic_props,cl_test_loss = classic_lda.train_classic_lda(train_mat, test_mat, vocab_size,ntopics, n_epochs )\n",
    "cl_end = time.time()\n",
    "cl_coherence = lda_vae.UCI_coherence(cl_topic_props, test_mat, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/plotnine/ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/plotnine/ggplot.py:719: PlotnineWarning: Filename: vae_lda_loss.png\n"
     ]
    }
   ],
   "source": [
    "vae_loss_df = pd.DataFrame().assign(epoch = list(range(15))[1:], loss = vae_test_loss[1:] )\n",
    "p2 = (\n",
    "    pn.ggplot(vae_loss_df) + \n",
    "    pn.geom_line(pn.aes(x='epoch', y=\"loss\")) + \n",
    "    pn.ggtitle(\"Loss(ELBO) on heldout data, VAE-LDA\") + \n",
    "    pn.theme_minimal()\n",
    ")\n",
    "p2.save(dpi=100, filename = \"vae_lda_loss.png\",transparent=False, facecolor='white' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/plotnine/ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/plotnine/ggplot.py:719: PlotnineWarning: Filename: classic_lda_loss.png\n"
     ]
    }
   ],
   "source": [
    "cl_loss_df = pd.DataFrame().assign(epoch = list(range(len(cl_test_loss[1:]))), loss = cl_test_loss[1:] )\n",
    "p1 = (\n",
    "    pn.ggplot(cl_loss_df) + \n",
    "    pn.geom_line(pn.aes(x='epoch', y=\"loss\")) + \n",
    "    pn.ggtitle(\"Loss(perplexity) on heldout data, classic-LDA\") + \n",
    "    pn.theme_minimal()\n",
    ")\n",
    "p1.save(dpi=100, filename = \"classic_lda_loss.png\",transparent=False, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/plotnine/ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/data/vss2134/miniconda/envs/sctopic/lib/python3.10/site-packages/plotnine/ggplot.py:719: PlotnineWarning: Filename: uci_coherence.png\n"
     ]
    }
   ],
   "source": [
    "topic_coherence_df = pd.DataFrame().assign(vae_lda = vae_coherence, classic_lda = cl_coherence).melt(var_name=\"algorithm\", value_name= \"UCI coherence\")\n",
    "p3 = (\n",
    "    pn.ggplot(topic_coherence_df, pn.aes(x= \"algorithm\", y=\"UCI coherence\")) + \n",
    "    pn.geom_violin() +\n",
    "    pn.geom_boxplot(width = .1)+\n",
    "    pn.ggtitle(\"UCI coherence on calculated topics using top 25 word per topic\")+\n",
    "    pn.theme_minimal()\n",
    ")\n",
    "p3.save(dpi=100, filename = \"uci_coherence.png\",transparent=False, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm\n",
       "classic_lda   -1.623975\n",
       "vae_lda       -1.684038\n",
       "Name: UCI coherence, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_coherence_df.groupby(\"algorithm\")['UCI coherence'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sctopic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397e19792fb5eec19bd5db264e145b80597572f49ea7a19f61a4c1e508a12bb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
